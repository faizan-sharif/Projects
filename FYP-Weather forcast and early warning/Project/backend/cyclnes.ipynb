{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.12.1' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '\"c:/Program Files/Python312/python.exe\" -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"typhoon.ipynb\n",
    "\n",
    "Automatically generated by Colaboratory.\n",
    "\n",
    "Original file is located at\n",
    "    https://colab.research.google.com/drive/1TH8ooY8N_qrzOlY11mrrf2JAlaVrF_RV\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from matplotlib import pyplot as plt\n",
    "from geopy.distance import great_circle\n",
    "\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import accuracy_score\n",
    "import sklearn.metrics\n",
    "\n",
    "import torch\n",
    "import torch.utils.data as Data\n",
    "import datetime\n",
    "\n",
    "import os\n",
    "import random\n",
    "\n",
    "# forecast 24-hour lead time\n",
    "pre_seq = 4\n",
    "batch_size = 128\n",
    "epochs = 128\n",
    "min_val_loss = 100\n",
    "model_name = '/content/drive/My Drive/Colab Notebooks/typhoon/model_saver/Model.pkl'\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from torch.nn.parameter import Parameter\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import math\n",
    "train = pd.read_csv('/content/drive/My Drive/Colab Notebooks/typhoon/data/CMA_train_'+str(pre_seq*6)+'h.csv', header=None)\n",
    "test= pd.read_csv('/content/drive/My Drive/Colab Notebooks/typhoon/data/CMA_test_'+str(pre_seq*6)+'h.csv', header=None)\n",
    "\n",
    "train.shape, test.shape\n",
    "\n",
    "class LSTM(nn.Module):\n",
    "\n",
    "    def __init__(self, num_classes, input_size, hidden_size, num_layers):\n",
    "        super(LSTM, self).__init__()\n",
    "\n",
    "        self.num_classes = num_classes\n",
    "        self.num_layers = num_layers\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.lstm = nn.LSTM(input_size=input_size, hidden_size=hidden_size,\n",
    "                            num_layers=num_layers, batch_first=True)\n",
    "\n",
    "        self.fc = nn.Linear(hidden_size, num_classes)\n",
    "\n",
    "    def forward(self, x,test=0):\n",
    "        x = x.unsqueeze(1)\n",
    "        h_0 = Variable(torch.zeros(\n",
    "            self.num_layers, x.size(0), self.hidden_size))\n",
    "\n",
    "        c_0 = Variable(torch.zeros(\n",
    "            self.num_layers, x.size(0), self.hidden_size))\n",
    "        ula, (h_out, _) = self.lstm(x, (h_0, c_0))\n",
    "\n",
    "        h_out = h_out.view(-1, self.hidden_size)\n",
    "\n",
    "        out = self.fc(h_out)\n",
    "\n",
    "        return out\n",
    "\n",
    "class TrainLoader(Data.Dataset):\n",
    "    def __init__(self, X_wide_train, y_train):\n",
    "        self.X_wide_train = X_wide_train\n",
    "        self.y_train = y_train\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.X_wide_train[index], self.y_train[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X_wide_train)\n",
    "\n",
    "\n",
    "CLIPER_feature =  pd.concat((train, test), axis=0)\n",
    "CLIPER_feature.reset_index(drop=True, inplace=True)\n",
    "\n",
    "X_wide_scaler = MinMaxScaler()\n",
    "y_scaler = MinMaxScaler()\n",
    "\n",
    "X_wide = X_wide_scaler.fit_transform(CLIPER_feature.iloc[:, 6:])\n",
    "X_wide_train = X_wide[0: train.shape[0], :]\n",
    "\n",
    "y = y_scaler.fit_transform(CLIPER_feature.loc[:, 3:4])\n",
    "\n",
    "\n",
    "#****** modified\n",
    "\n",
    "\n",
    "y_train = y[0: train.shape[0], :]\n",
    "\n",
    "print(\"************************************************\")\n",
    "print(len(X_wide_train))\n",
    "print(len(y_train))\n",
    "\n",
    "#********** here is the code for extracting test code\n",
    "# X_wide_test = X_wide[train.shape[0]: , :]\n",
    "# y_test = y[train.shape[0]: , :]\n",
    "\n",
    "# print(len(X_wide_test))\n",
    "# print(len(y_test))\n",
    "\n",
    "\n",
    "\n",
    "learning_rate = 0.01\n",
    "\n",
    "input_size = 53\n",
    "hidden_size = 128\n",
    "num_layers = 1\n",
    "\n",
    "num_classes = 2\n",
    "\n",
    "model = LSTM(num_classes, input_size, hidden_size, num_layers)\n",
    "\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    model.cuda()\n",
    "\"\"\"# Training\"\"\"\n",
    "\n",
    "criterion = nn.L1Loss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "full_train_index = [*range(0, len(X_wide_train))]\n",
    "\n",
    "for epoch in range(epochs):  # loop over the dataset multiple times\n",
    "    starttime = datetime.datetime.now()\n",
    "    train_index, val_index, _, _, = train_test_split(full_train_index, full_train_index, test_size=0.1)\n",
    "    \n",
    "    train_dataset = torch.utils.data.DataLoader(\n",
    "    TrainLoader(X_wide_train[train_index],y_train[train_index]), \n",
    "                                                 batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    val_dataset = torch.utils.data.DataLoader(\n",
    "    TrainLoader(X_wide_train[val_index], y_train[val_index]), \n",
    "                                                 batch_size=batch_size, shuffle=True)\n",
    "    \n",
    "      \n",
    "    # training\n",
    "    total_train_loss = 0\n",
    "    for step, (batch_x, batch_y) in enumerate(train_dataset):\n",
    "        X_wide_train_cuda = batch_x.float()\n",
    "      \n",
    "        y_train_cuda = batch_y\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "        # forward + backward + optimize\n",
    "        pred_y = model(X_wide_train_cuda)\n",
    "        loss = criterion(pred_y, y_train_cuda)\n",
    "        total_train_loss += loss.item()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    # validation\n",
    "    total_val_loss = 0\n",
    "    for _, (batch_val_x, batch_val_y) in enumerate(val_dataset):\n",
    "\n",
    "       \n",
    "        X_wide_val_cuda = batch_val_x.float()\n",
    "        y_val_cuda = batch_val_y\n",
    "\n",
    "        pred_y = model(X_wide_val_cuda)\n",
    "        val_loss = criterion(pred_y, y_val_cuda)\n",
    "        total_val_loss += val_loss.item()\n",
    "\n",
    "        # print statistics\n",
    "    if min_val_loss > total_val_loss:\n",
    "        torch.save(model.state_dict(), model_name)\n",
    "        min_val_loss = total_val_loss\n",
    "    endtime = datetime.datetime.now()\n",
    "    print('epochs [%d/%d] cost:%.2fs train_loss: %.5f val_loss: %.5f' %\n",
    "          (epoch + 1, epochs, (endtime - starttime).seconds, total_train_loss, total_val_loss))\n",
    "\n",
    "print('Finished Training')\n",
    "\n",
    "# here is the code for the testing\n",
    "\n",
    "# net.load_state_dict(torch.load(model_name))\n",
    "years = test[5].unique()\n",
    "test_list = []\n",
    "\n",
    "for year in years:\n",
    "    temp = test[test[5] == year]\n",
    "    temp = temp.reset_index(drop=True)\n",
    "    test_list.append(temp)\n",
    "\n",
    "len(test_list)\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# net = model\n",
    "# net = net.to(device)\n",
    "model.load_state_dict(torch.load(model_name))\n",
    "\n",
    "#model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    for year, _test in zip(years, test_list):\n",
    "\n",
    "        print(year, 'Ã¥Â¹Â´:')\n",
    "\n",
    "        y_test_lat = _test.loc[:, 3]\n",
    "\n",
    "        y_test_long = _test.loc[:, 4]\n",
    "\n",
    "        X_wide_test = X_wide_scaler.transform(_test.loc[:, 6:])\n",
    "        #X_wide_test = X_wide_scaler.fit|_transform(_test.loc[:, 6:])\n",
    "       # X_wide_test = _test.loc[:, 6:]\n",
    "\n",
    "        final_test_list = []\n",
    "\n",
    "\n",
    "\n",
    "        # if torch.cuda.is_available():\n",
    "        X_wide_test = Variable(torch.from_numpy(X_wide_test).float())\n",
    "        #X_wide_test = X_wide_test.float().cuda()\n",
    "        pred = model(X_wide_test)\n",
    "\n",
    "        pred = y_scaler.inverse_transform(pred.cpu().detach().numpy())\n",
    "\n",
    "        pred_lat = pred[:, 0]\n",
    "        pred_long = pred[:, 1]\n",
    "        true_lat = y_test_lat\n",
    "        true_long = y_test_long\n",
    "\n",
    "        diff_lat = np.abs(pred_lat - true_lat)\n",
    "        diff_long = np.abs(pred_long - true_long)\n",
    "\n",
    "        print('avg lat:', sum(diff_lat) / len(diff_lat))\n",
    "        print('avg long:', sum(diff_long) / len(diff_long))\n",
    "\n",
    "        sum_error = []\n",
    "        for i in range(0, len(pred_lat)):\n",
    "            sum_error.append(great_circle((pred_lat[i], pred_long[i]), (true_lat[i], true_long[i])).kilometers)\n",
    "\n",
    "        print('avg distance error:', sum(sum_error) / len(sum_error))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
